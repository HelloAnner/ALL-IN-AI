{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "参考： https://python.langchain.com/en/latest/modules/models/chat/examples/few_shot_examples.html\n",
    "\n",
    "这里介绍一下如何给模型一个例子，告诉它什么是正确的输入和输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-09T20:04:39.721527Z",
     "end_time": "2023-05-09T20:04:40.839717Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI语言模型，由OpenAI开发。"
     ]
    },
    {
     "data": {
      "text/plain": "AIMessage(content='我是一个AI语言模型，由OpenAI开发。', additional_kwargs={}, example=False)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0)\n",
    "\n",
    "chat([HumanMessage(content=\"你是谁\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "即在构建 prompt 模版对象的时候中间的参数可以给出示例的输入和输出"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-09T20:05:04.895931Z",
     "end_time": "2023-05-09T20:05:05.770807Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I be lovin' programmin', me hearty!"
     ]
    },
    {
     "data": {
      "text/plain": "\"I be lovin' programmin', me hearty!\""
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"You are a helpful assistant that translates english to pirate.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "example_human = HumanMessagePromptTemplate.from_template(\"Hi\")\n",
    "example_ai = AIMessagePromptTemplate.from_template(\"Argh me mateys\")\n",
    "\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, example_human, example_ai, human_message_prompt])\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "# get a chat completion from the formatted messages\n",
    "chain.run(\"I love programming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "openAI 提供了一个 name 参数来辅助帮助ai理解自己的角色。 和上述的例子不同的是，这里都是 systemMessage ，我理解这是无奈之举。 也可以理解，既然是 openai提供的接口，当然交给模型提供方去完成对应的构建。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T20:16:44.900584Z",
     "end_time": "2023-05-09T20:16:45.894813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I be lovin' programmin', me hearty."
     ]
    },
    {
     "data": {
      "text/plain": "\"I be lovin' programmin', me hearty.\""
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"You are a helpful assistant that translates english to pirate.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "example_human = SystemMessagePromptTemplate.from_template(\"Hi\", additional_kwargs={\"name\": \"example_user\"})\n",
    "example_ai = SystemMessagePromptTemplate.from_template(\"Argh me mateys\",\n",
    "                                                       additional_kwargs={\"name\": \"example_assistant\"})\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, example_human, example_ai, human_message_prompt])\n",
    "chain = LLMChain(llm=chat, prompt=chat_prompt)\n",
    "# get a chat completion from the formatted messages\n",
    "chain.run(\"I love programming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "在上述例子中，虽然将chat构建为stream的形式输出，但是每一次都是在默认调用callback ，和返回值同时输出，比较难受。\n",
    "\n",
    "介绍一下将 response 流式输出，而不是单纯的输出到控制台中: https://python.langchain.com/en/latest/modules/models/chat/examples/streaming.html\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个AI语言模型，由OpenAI开发。"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    ")\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0)\n",
    "resp = chat([HumanMessage(content=\"你是谁\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T20:20:17.771303Z",
     "end_time": "2023-05-09T20:20:18.777259Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
